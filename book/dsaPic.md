# 算法图解

> 算法图解介绍了很多常用的算法，以图的形式让读者有更清晰的认识。

## 目录

1. [基本概念](#基本概念)
   1. [大 O 表示法](#大O表示法)
   2. [常见的大 O 运行时间](#常见的大O运行时间)
   3. [递归](#递归)
2. [排序算法](#排序算法)
   1. [选择排序](#选择排序)
   2. [快速排序](#快速排序)
3. [散列表](#散列表)
4. [广度优先算法](#广度优先算法)
5. [狄克斯特拉算法](#狄克斯特拉算法)
6. [贪婪算法](#贪婪算法)
7. [动态规划](#动态规划)
8. [K 最邻算法](#K最邻算法)

## 基本概念

在算法的学习过程中，有一些基本的概念知识需要我们提前了解。

### 大 O 表示法

大 O 表示法的作用是衡量算法有多快，它指出了算法的运行时间的增速（注意是增速）。

其次，它表示的是算法最糟情况下的表现。

### 常见的大 O 运行时间

- O(log n)
- O(n)
- O(n * log n)
- O(n^2)
- O(n!)

### 递归

递归是一种优雅的问题解决方案。

他指的就是自己调用自己的函数。

## 排序算法

排序算法是算法中非常基础，同时使用频率非常高的一类算法。下面将介绍一些常用的排序算法。

### 选择排序

选择排序的方法是在一堆数据中，每次都选出最大/小的数据放在数据头部，这样就能够完成排序。那么我们分析一下选择排序的运行时间。

我们每次都要将所有数据扫描一遍，选出最大/小值，所以每一趟排序的时间复杂度都是 O(n)。我们有 n 个数，所以时间复杂度为 O(n^2)。

但是我们实际操作一遍就会发现，我们在排序的过程中，每一次需要检查的数会越来越少，所以，平均下来每次需要检查的数量为 1/2 * n，因此，运行时间为 O(n * 1/2 * n)，但大 O 表示法省略常数，则最后为 O(n^2)。

### 快速排序

这一种典型的分而治之思想的算法，也是一种著名的递归式问题的解决方案。

那么如何完成这种分而治之的问题的呢？

第一、找出简单的基线条件。

第二、确定如何缩小问题的规模，使其符合基线条件。

一般来说涉及到数组的递归函数，基线条件通常是数组为空或者只包含一个元素。

那么快速排序是怎么实现的呢？

1. 找一个基准值
2. 将比基准值小的放左边，比基准值大的放右边（这个步骤叫分区）
3. 对这两个子数组进行快速排序

快速排序的速度取决于基准值的选择，在基准值最遭的情况下，时间复杂度为 O(n^2)。

这里有一个比较就是，归并排序运行时间总是 O(n * log n)，而快排的平均时间和归并一样，为什么我们不使用归并，而要使用快排呢？

归并需要额外的空间，同时，快排要退化成 O(n^2) 的概率是非常小的。

## 散列表

散列表会通过散列函数将相同的输入映射到相同的结果，不同的输入映射到不同的结果。

语言本身是实现了一个散列函数的，所以我们通常使用 hashMap 速度会很快，那么判断一个散列表是否是一个优秀的散列表的一个标准就是，避开冲突，保证映射平均分布在内存中。

## 广度优先算法

这是一种图的算法，他能够让我们快速的找到两个东西之间的最短距离。

第一类问题：从节点A出发，有前往节点B的路径吗？

第二类问题：从节点A出发，前往节点B的哪条路径最短？

这个算法所用到的数据结构是队列，这是一种不支持随机访问，一种先进先出 (FIFO) 的结构。

## 狄克斯特拉算法

这也是一种图的算法，但是这是针对于加权图的算法，这次理解的不是很深刻，接下来要继续去学习。

## 贪婪算法

贪婪算法的优点是简单易行，它能够得到的是相对最优解，而不是绝对最优解，每一步都寻找的是局部最优解。贪婪算法易于实现、运行速度快，是不错的近似算法。对于某些问题来说，要得到最优解是非常复杂麻烦的，使用近似算法反而是一个不错的选择。

## 动态规划

动态规划是一个说起来简单，但是自己做起来有感觉摸不着头脑的那种问题。

根据书里说的动态规划都可以放在一个网格里进行计算，我们可以通过一步一步的解决小问题，最后得到整个问题的答案，这个还要下去验证，这也是一种思路。

## K 最邻算法

这是一个可以用来做分类和回归的算法，比如说推荐系统，这个就不研究了，有兴趣再说吧。